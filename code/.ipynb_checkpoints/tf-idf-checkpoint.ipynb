{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from clean_data import clean_data\n",
    "from itertools import repeat\n",
    "import numpy as np\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../StateNames.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fem = df[df['Gender']=='F']\n",
    "fem = fem.drop(['Id', 'Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = fem[:20]\n",
    "subset = subset.drop(['Gender', 'Id', 'Count', 'count_norm'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# year_doc = []\n",
    "# for index, row in asdf[(asdf.index.get_level_values(level=0)==1910) & (asdf.index.get_level_values(level=1)=='AK')].iterrows():\n",
    "#     year_doc.extend([row['new_name']] * row['Count_by_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# docs = []\n",
    "\n",
    "# for item in subset.tuple_index.unique():\n",
    "#     names = []\n",
    "#     single_doc = []\n",
    "#     frame = subset[subset.tuple_index==item]\n",
    "    \n",
    "#     for line in next(frame.iterrows())[1]:\n",
    "#         print \"line: {}\".format(line)\n",
    "#     for i in frame.new_name.values: \n",
    "        \n",
    "#         print len([i]*frame.iloc[0]['Count_by_name'])\n",
    "#         single_doc += names\n",
    "#     docs.append(single_doc)\n",
    "#     print subset.new_name.values * subset.Count_by_name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# docs = []\n",
    "\n",
    "# for index, row in subset.iterrows():\n",
    "#     year_doc = []\n",
    "# #     for i in index:\n",
    "#     year_doc.extend(repeat(row['new_name'], row['Count_by_name']))\n",
    "#     docs.append(year_doc)\n",
    "\n",
    "# for index, row in subset.iterrows():\n",
    "#     year_doc = []\n",
    "#     for i in index:\n",
    "#         for j in xrange(row['Count_by_name']):\n",
    "#             year_doc.append(row['new_name'])\n",
    "#     docs.append(year_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# docs_list = []\n",
    "# for (year, state) in subset.index:\n",
    "# #     count = subset[(subset.index.get_level_values(level=0)==year) & \n",
    "# #                    (subset.index.get_level_values(level=1)==state)]['Count_by_name']\n",
    "# #     name = subset[(subset.index.get_level_values(level=0)==year) & \n",
    "# #                (subset.index.get_level_values(level=1)==state)]['new_name']\n",
    "#     df = subset[(subset.index.get_level_values(level=0)==year) & \n",
    "#                (subset.index.get_level_values(level=1)==state)]\n",
    "#     name = df.new_name\n",
    "#     docs_list.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grouped = asdf.groupby(['tuple_index','new_name']).sum()['Count_by_name']\n",
    "# asdf['tupled'] = zip(asdf.new_name, asdf.Count_by_name)\n",
    "# count_series = asdf.tupled\n",
    "# count_dict = count_series.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this format doesn't work with the vectorizer classes\n",
    "def documentizer(df):\n",
    "    docs = []\n",
    "    for (year, state) in set(df.index.values):\n",
    "        year_doc = []\n",
    "        for index, row in df[(df.index.get_level_values(level=0)==year) & (df.index.get_level_values(level=1)==state)].iterrows():\n",
    "            year_doc.extend([row['new_name']] * row['Count_by_name'])\n",
    "        docs.append(year_doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# docs = []\n",
    "# for (year, state) in set(subset.index.values):\n",
    "#     year_doc = []\n",
    "#     for index, row in subset[(subset.index.get_level_values(level=0)==year) & (subset.index.get_level_values(level=1)==state)].iterrows():\n",
    "#         year_doc.extend([row['new_name']] * row['Count_by_name'])\n",
    "#     docs.append(year_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fem_docs = documentizer(fem) \n",
    "#this format doesn't work with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vocab_set = set()\n",
    "# [[vocab_set.add(token) for token in tokens] for tokens in fem_docs]\n",
    "# vocab = list(vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# matrix = [[0] * len(vocab) for doc in fem_docs]\n",
    "# vocab_dict = dict((word, i) for i, word in enumerate(vocab))\n",
    "\n",
    "# for i, words in enumerate(fem_docs):\n",
    "#     for word in words:\n",
    "#         matrix[i][vocab_dict[word]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fem_sub = fem.iloc[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def document_transform(df):\n",
    "    docs = []\n",
    "    for (year, state) in sorted(set(df.index.values)):\n",
    "        year_str = '' \n",
    "        for index, row in df[(df.index.get_level_values(level=0)==year) & (df.index.get_level_values(level=1)==state)].iterrows():\n",
    "            year_str += ((row['new_name']+' ') * row['Count_by_name'])\n",
    "        docs.append(year_str)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male[male.Gender=='M'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fem_docs = document_transform(fem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<63x415 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 5000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "vectors = tfidf.fit_transform(fem_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array_vec = vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_values(lst, n, labels):\n",
    "    '''\n",
    "    INPUT: LIST, INTEGER, LIST\n",
    "    OUTPUT: LIST\n",
    "\n",
    "    Given a list of values, find the indices with the highest n values.\n",
    "    Return the labels for each of these indices.\n",
    "    '''\n",
    "    return [labels[i] for i in np.argsort(lst)[-1:-n-1:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# avg = np.sum(array_vec,axis=0) / np.sum(array_vec>0,axis=0)\n",
    "# print \"top 10 by average tf-idf\"\n",
    "# print get_top_values(avg, 20, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# total = np.sum(array_vec, axis=0)\n",
    "# print \"top 10 by total tf-idf\"\n",
    "# print get_top_values(total, 20, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorizer2 = TfidfVectorizer(use_idf=False)\n",
    "# # make documents into one giant document for this purpose\n",
    "# vectors2 = vectorizer2.fit_transform(fem_docs).toarray()\n",
    "# print \"top 10 by tf across all corpus\"\n",
    "# print get_top_values(vectors2[0], 10, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fem_index = sorted(set(fem.index.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re_df = pd.DataFrame(data=vectors, index=fem_index, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W, H, fem_nmf = run_nmf(array_vec, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# W = pd.DataFrame(W, index=fem_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# H = pd.DataFrame(H, columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_index = H.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_nmf(df,params):\n",
    "    nmf = NMF(n_components=params)\n",
    "    W = nmf.fit_transform(df)\n",
    "    H = nmf.components_\n",
    "    return W, H, nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_features(W, H, features, top_features):\n",
    "    for latent_num, latent in enumerate(H):\n",
    "        print \"Latent Feature %d\" % (int(latent_num) + 1)\n",
    "        print [features[i] for i in latent.argsort()[:-top_features-1:-1]]\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent Feature 1\n",
      "[u'betty', u'barbara', u'shirley', u'mary', u'patricia', u'joan', u'joyce', u'dorothy', u'carol', u'beverly', u'marilyn', u'doris', u'phyllis', u'nancy', u'lois', u'jean', u'donna', u'norma', u'dolores', u'gloria']\n",
      "\n",
      "Latent Feature 2\n",
      "[u'ashley', u'jessica', u'brittany', u'samantha', u'kayla', u'megan', u'taylor', u'amanda', u'lauren', u'emily', u'hannah', u'sarah', u'courtney', u'amber', u'kelsey', u'nicole', u'chelsea', u'alyssa', u'danielle', u'alexis']\n",
      "\n",
      "Latent Feature 3\n",
      "[u'madison', u'isabella', u'abigail', u'ava', u'olivia', u'emma', u'sophia', u'chloe', u'addison', u'alexis', u'hannah', u'hailey', u'emily', u'mia', u'taylor', u'avery', u'brooklyn', u'nevaeh', u'kaylee', u'lily']\n",
      "\n",
      "Latent Feature 4\n",
      "[u'linda', u'mary', u'patricia', u'susan', u'sharon', u'sandra', u'karen', u'deborah', u'barbara', u'carol', u'debra', u'nancy', u'diane', u'donna', u'judy', u'judith', u'pamela', u'kathleen', u'cheryl', u'brenda']\n",
      "\n",
      "Latent Feature 5\n",
      "[u'lisa', u'tammy', u'kimberly', u'lori', u'michelle', u'karen', u'debra', u'julie', u'pamela', u'susan', u'tina', u'brenda', u'cynthia', u'tracy', u'angela', u'teresa', u'deborah', u'rhonda', u'dawn', u'kim']\n",
      "\n",
      "Latent Feature 6\n",
      "[u'mary', u'annie', u'willie', u'betty', u'ruby', u'dorothy', u'mildred', u'lillie', u'mattie', u'martha', u'bessie', u'thelma', u'louise', u'minnie', u'ethel', u'edna', u'gladys', u'frances', u'hazel', u'lula']\n",
      "\n",
      "Latent Feature 7\n",
      "[u'jennifer', u'jessica', u'melissa', u'heather', u'amanda', u'amy', u'nicole', u'michelle', u'kimberly', u'stephanie', u'angela', u'sarah', u'tiffany', u'crystal', u'kelly', u'christina', u'shannon', u'erin', u'rebecca', u'amber']\n",
      "\n",
      "Latent Feature 8\n",
      "[u'mary', u'helen', u'dorothy', u'margaret', u'ruth', u'mildred', u'florence', u'frances', u'alice', u'elizabeth', u'evelyn', u'doris', u'irene', u'virginia', u'anna', u'marie', u'gladys', u'gertrude', u'marjorie', u'lillian']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_features(W,H,names,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transpose = array_vec.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_, H_, fem_name_nmf = run_nmf(transpose, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent Feature 1\n",
      "[(1913, 'MI'), (1914, 'MI'), (1912, 'MI'), (1915, 'MI'), (1911, 'MI'), (1916, 'MI'), (1915, 'IL'), (1915, 'MT'), (1916, 'IL'), (1910, 'MI'), (1914, 'IL'), (1913, 'WA'), (1913, 'IL'), (1917, 'MT'), (1917, 'MI'), (1910, 'WA'), (1918, 'NJ'), (1912, 'MT'), (1916, 'MN'), (1912, 'WA')]\n",
      "\n",
      "Latent Feature 2\n",
      "[(1993, 'KY'), (1994, 'WV'), (1992, 'IN'), (1993, 'TN'), (1993, 'IN'), (1994, 'KY'), (1994, 'TN'), (1992, 'MO'), (1992, 'OH'), (1993, 'WV'), (1993, 'NC'), (1993, 'OH'), (1992, 'KY'), (1993, 'VA'), (1991, 'IN'), (1993, 'AL'), (1993, 'AR'), (1992, 'TN'), (1993, 'MI'), (1994, 'AR')]\n",
      "\n",
      "Latent Feature 3\n",
      "[(2009, 'MO'), (2009, 'OH'), (2009, 'MI'), (2010, 'OH'), (2010, 'MI'), (2010, 'PA'), (2009, 'IN'), (2011, 'VA'), (2010, 'MO'), (2011, 'PA'), (2010, 'VA'), (2011, 'NC'), (2009, 'PA'), (2011, 'MI'), (2011, 'OH'), (2010, 'NC'), (2009, 'KS'), (2008, 'OH'), (2012, 'VA'), (2010, 'IN')]\n",
      "\n",
      "Latent Feature 4\n",
      "[(1966, 'OK'), (1966, 'MT'), (1965, 'IN'), (1965, 'KS'), (1967, 'KS'), (1966, 'KS'), (1965, 'IA'), (1966, 'IN'), (1965, 'MT'), (1964, 'IN'), (1966, 'IA'), (1966, 'ND'), (1966, 'NE'), (1966, 'ID'), (1965, 'OK'), (1966, 'MO'), (1963, 'IN'), (1965, 'ID'), (1965, 'MO'), (1966, 'MI')]\n",
      "\n",
      "Latent Feature 5\n",
      "[(1978, 'NV'), (1977, 'WY'), (1977, 'NV'), (1978, 'OH'), (1979, 'NV'), (1978, 'IN'), (1978, 'CO'), (1977, 'CO'), (1978, 'KS'), (1978, 'WA'), (1977, 'KS'), (1977, 'WA'), (1977, 'IN'), (1978, 'IA'), (1979, 'NH'), (1978, 'MI'), (1979, 'SD'), (1978, 'MO'), (1977, 'OR'), (1979, 'MI')]\n",
      "\n",
      "Latent Feature 6\n",
      "[(1950, 'OR'), (1950, 'MI'), (1950, 'WA'), (1949, 'OR'), (1949, 'WA'), (1950, 'NV'), (1949, 'IN'), (1950, 'OH'), (1949, 'CA'), (1948, 'WA'), (1951, 'OR'), (1949, 'MI'), (1951, 'MI'), (1950, 'CA'), (1950, 'IN'), (1950, 'ID'), (1948, 'OR'), (1949, 'ID'), (1949, 'OH'), (1950, 'CO')]\n",
      "\n",
      "Latent Feature 7\n",
      "[(1918, 'MS'), (1917, 'MS'), (1919, 'MS'), (1916, 'MS'), (1913, 'AL'), (1915, 'MS'), (1920, 'MS'), (1913, 'MS'), (1912, 'AL'), (1925, 'MS'), (1914, 'MS'), (1922, 'MS'), (1915, 'AL'), (1929, 'MS'), (1914, 'AL'), (1927, 'MS'), (1926, 'MS'), (1923, 'MS'), (1916, 'AL'), (1913, 'GA')]\n",
      "\n",
      "Latent Feature 8\n",
      "[(1932, 'WA'), (1932, 'OR'), (1931, 'WA'), (1935, 'NE'), (1935, 'IL'), (1935, 'MI'), (1934, 'OR'), (1934, 'ID'), (1934, 'NE'), (1935, 'IA'), (1935, 'KS'), (1931, 'OR'), (1935, 'OR'), (1934, 'WA'), (1933, 'OR'), (1935, 'ID'), (1933, 'NE'), (1935, 'WA'), (1930, 'WA'), (1934, 'IL')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_features(W_,H_,fem_index,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5355"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20031, 8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##MALE NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   2.20793929e-07\n",
      "   0.00000000e+00   0.00000000e+00]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[  4.57530503e-03   3.68065258e-03   7.53113339e-04 ...,   5.09132574e-05\n",
      "   1.14602785e-03   5.14669154e-04]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "   0.00000000e+00   5.00803998e-07]\n",
      "[  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "   2.97104591e-06   0.00000000e+00]\n",
      "[  0.00000000e+00   0.00000000e+00   2.61221681e-05 ...,   2.21473167e-06\n",
      "   0.00000000e+00   0.00000000e+00]\n",
      "[  1.24312599e-05   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# male = df[df['Gender']=='M']\n",
    "male = male.drop(['Id', 'Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
